import os, json, time, boto3, traceback, pymysql, datetime, configparser

cloudSearchClient = boto3.client('cloudsearch')
cloudSearchDomainClient = None

domain = "twitter"
path = "file/tweet_"
counter = 0
file = None

# Credential dictionary
credentials = {}

# Database connection global variable
connection = None

def getCloudSearchDomainName():
    response = cloudSearchClient.list_domain_names()
    if(len(response['DomainNames']) != 0):
        # Use the first domain found
        domainName = list(response['DomainNames'])[0]
        return domainName
    # Create and confirgure a new domain if there is no domain yet
    else:
        createDomainResponse = cloudSearchClient.create_domain(DomainName = domain)
        print(">>> Please wait 10 minutes while the domain is being created...")
        # Wait for 10 minutes...
        time.sleep(600)
        setCloudSearchPolicy(domain)
        setIndices(domain)
        startIndexing(domain)
        return createDomainResponse['DomainStatus']['DomainName']

def setCloudSearchPolicy(domainName):
    # Set cloudsearch policy as
    # Search and Suggester Service: Allow all
    # Document Service: Account owner only
    policy = {
        "Version": "2012-10-17",
            "Statement": [
            {
                "Effect": "Allow",
                "Principal": {
                    "AWS": [
                      "*"
                    ]
                },
                "Action": [
                    "cloudsearch:search",
                    "cloudsearch:suggest"
                ]
            }
        ]
    }
    accessPolicy = json.dumps(policy)
    policyResponse = cloudSearchClient.update_service_access_policies(
        DomainName = domainName,
        AccessPolicies = json.dumps(policy))
    print(">>> Please wait 10 minutes while the policy is being processed...")
    # Wait for 10 minutes...
    time.sleep(600)

def setIndices(domainName):
    indices = [
        {"IndexFieldName": "coordinates", "IndexFieldType": "latlon"},
        {"IndexFieldName": "time", "IndexFieldType": "date"},
        {"IndexFieldName": "tweet", "IndexFieldType": "text"}
    ]
    # Set indices to override the configuration
    for index in indices:
        indexResponse = cloudSearchClient.define_index_field(
            DomainName = domainName,
            IndexField = index)
    print(">>> Please wait 15 seconds while the indices are being compiled...")
    # Wait for 15 seconds...
    time.sleep(15)

def startIndexing(domainName):
    confirmed = input(">>> Warning: Re-indexing for all documents? (y/n)")
    # Double confirm before costy operation
    if confirmed == 'y' or confirmed == 'Y':
        indexResponse = cloudSearchClient.index_documents(DomainName = domainName)
        print(indexResponse)
        print(">>> Please wait 10 minutes while the indices are being compiled...")
        # Wait for 10 minutes...
        time.sleep(600)
    else:
        pass

# Get search endpoint URL by describing domains
def getEndPoint():
    return cloudSearchClient.describe_domains()['DomainStatusList'][0]['SearchService']['Endpoint']

# Upload data previous generated by getter
def uploadFiles():
    global counter
    # Find the nearest un-uploaded file (without .lock file)
    while os.path.isfile(getCurrentLockFilename()):
        print(getCurrentLockFilename())
        counter = counter + 1
    while True:
        # Wait for starting of the next file, which means previous file must be completely finished
        while os.path.isfile(getNextFilename()) == False:
            # deleteOldDataFromDatabase()
            time.sleep(20)
        # Open previous written file to encode string data to bytes
        f = open(getCurrentFilename(), 'r')
        uploadText = str.encode(f.read())
        f.close()
        # Upload file content to cloudsearch server
        uploadResponse = cloudSearchDomainClient.upload_documents(
            documents = uploadText,
            contentType = 'application/json')
        print(uploadResponse)
        # Generate .lock file for uploaded data file
        file = open(getCurrentLockFilename(), "a")
        file.close()
        counter = counter + 1

# Get filename to determine whether file has been uploaded
def getCurrentLockFilename():
    return path + str(counter) + ".lock"

# Get filename to determine whether next file is being created
def getNextFilename():
    return path + str(counter + 1) + ".json"

def getCurrentFilename():
    return path + str(counter) + ".json"

def deleteOldDataFromDatabase():
    # Delete records before 30 minutes
    oldTime = datetime.datetime.utcnow() - datetime.timedelta(seconds = 1800)
    # DELETE FROM tweets WHERE `time` < "2016-03-03 00:24:24"
    sql = "DELETE FROM `tweets` WHERE `time` < %s"
    cursor = connection.cursor()
    try:
        cursor.execute(sql, oldTime.strftime("%Y-%m-%d %H:%M:%S"))
    finally:
        connection.commit()
        cursor.close()

def initialize():
    global cloudSearchDomainClient, connection
    cloudSearchDomainName = getCloudSearchDomainName()
    cloudSearchDomainClient = boto3.client("cloudsearchdomain", endpoint_url = "http://" + getEndPoint())
    # config = configparser.ConfigParser()
    # config.read("credentials.conf")
    # # Database credentials
    # credentials['database_host'] = config.get("MySQLConfiguration", "database_host")
    # credentials['database_port'] = config.get("MySQLConfiguration", "database_port")
    # credentials['database_user'] = config.get("MySQLConfiguration", "database_user")
    # credentials['database_password'] = config.get("MySQLConfiguration", "database_password")
    # credentials['database_db'] = config.get("MySQLConfiguration", "database_db")
    # # Initial connection, ensure using utf8mb4 to capture all characters
    # connection = pymysql.connect(
    #         host = credentials['database_host'], 
    #         port = int(credentials['database_port']),
    #         user = credentials['database_user'], 
    #         passwd = credentials['database_password'], 
    #         db = credentials['database_db'],
    #         charset = 'utf8mb4')

if __name__ == '__main__':   
    initialize()
    # Continuously upload new file being created
    while True:
        try:
            uploadFiles()
        except (KeyboardInterrupt, SystemExit):
            print("Quiting Uploader...")
            break
        except Exception:
            traceback.print_exc()
            print()
    # Close database connection on exit
    try:
        connection.close()
        print("Connection Close Finished")
    except:
        pass
